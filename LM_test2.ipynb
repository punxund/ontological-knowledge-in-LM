{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import string\n",
    "\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertForMaskedLM.from_pretrained('bert-base-uncased').eval()\n",
    "\n",
    "from transformers import XLNetTokenizer, XLNetLMHeadModel\n",
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "xlnet_model = XLNetLMHeadModel.from_pretrained('xlnet-base-cased').eval()\n",
    "\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForMaskedLM\n",
    "xlmroberta_tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "xlmroberta_model = XLMRobertaForMaskedLM.from_pretrained('xlm-roberta-base').eval()\n",
    "\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "bart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large').eval()\n",
    "\n",
    "from transformers import ElectraTokenizer, ElectraForMaskedLM\n",
    "electra_tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-generator')\n",
    "electra_model = ElectraForMaskedLM.from_pretrained('google/electra-small-generator').eval()\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta_model = RobertaForMaskedLM.from_pretrained('roberta-base').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(tokenizer, pred_idx):\n",
    "    ignore_tokens = string.punctuation + '[PAD]'\n",
    "    tokens = []\n",
    "    for w in pred_idx:\n",
    "        token = ''.join(tokenizer.decode(w).split())\n",
    "        if token not in ignore_tokens:\n",
    "            tokens.append(token.replace('##', ''))\n",
    "    return tokens[:10]\n",
    "\n",
    "\n",
    "def encode(tokenizer, text_sentence, add_special_tokens=True):\n",
    "    text_sentence = text_sentence.replace('<mask>', tokenizer.mask_token)\n",
    "    if tokenizer.mask_token == text_sentence.split()[-1]:\n",
    "        text_sentence += ' .'\n",
    "\n",
    "    input_ids = torch.tensor([tokenizer.encode(text_sentence, add_special_tokens=add_special_tokens)])\n",
    "    mask_idx = torch.where(input_ids == tokenizer.mask_token_id)[1].tolist()[0]\n",
    "    return input_ids, mask_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_sentence = 'Bremen is a <mask>.'\n",
    "def get_all_predictions(text_sentence):\n",
    "    # ========================= BERT =================================\n",
    "    input_ids, mask_idx = encode(bert_tokenizer, text_sentence)\n",
    "    with torch.no_grad():\n",
    "        predict = bert_model(input_ids)[0]\n",
    "    bert = decode(bert_tokenizer, predict[0, mask_idx, :].topk(10).indices.tolist())\n",
    "    #print(bert)\n",
    "    # ========================= XLNET LARGE =================================\n",
    "    input_ids, mask_idx = encode(xlnet_tokenizer, text_sentence, False)\n",
    "    perm_mask = torch.zeros((1, input_ids.shape[1], input_ids.shape[1]), dtype=torch.float)\n",
    "    perm_mask[:, :, mask_idx] = 1.0  \n",
    "    target_mapping = torch.zeros((1, 1, input_ids.shape[1]), dtype=torch.float)  \n",
    "    target_mapping[0, 0, mask_idx] = 1.0  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        predict = xlnet_model(input_ids, perm_mask=perm_mask, target_mapping=target_mapping)[0]\n",
    "    xlnet = decode(xlnet_tokenizer, predict[0, 0, :].topk(10).indices.tolist())\n",
    "    #print(xlnet)\n",
    "    # ========================= XLM ROBERTA BASE =================================\n",
    "    input_ids, mask_idx = encode(xlmroberta_tokenizer, text_sentence, add_special_tokens=True)\n",
    "    with torch.no_grad():\n",
    "        predict = xlmroberta_model(input_ids)[0]\n",
    "    xlm = decode(xlmroberta_tokenizer, predict[0, mask_idx, :].topk(10).indices.tolist())\n",
    "    #print(xlm)\n",
    "    # ========================= BART =================================\n",
    "    input_ids, mask_idx = encode(bart_tokenizer, text_sentence, add_special_tokens=True)\n",
    "    with torch.no_grad():\n",
    "        predict = bart_model(input_ids)[0]\n",
    "    bart = decode(bart_tokenizer, predict[0, mask_idx, :].topk(10).indices.tolist())\n",
    "    #print(bart)\n",
    "    # ========================= ELECTRA =================================\n",
    "    input_ids, mask_idx = encode(electra_tokenizer, text_sentence, add_special_tokens=True)\n",
    "    with torch.no_grad():\n",
    "        predict = electra_model(input_ids)[0]\n",
    "    electra = decode(electra_tokenizer, predict[0, mask_idx, :].topk(10).indices.tolist())\n",
    "    #print(electra)\n",
    "    # ========================= ROBERTA =================================\n",
    "    input_ids, mask_idx = encode(roberta_tokenizer, text_sentence, add_special_tokens=True)\n",
    "    with torch.no_grad():\n",
    "        predict = roberta_model(input_ids)[0]\n",
    "    roberta = decode(roberta_tokenizer, predict[0, mask_idx, :].topk(10).indices.tolist())\n",
    "    #print(roberta)\n",
    "    \n",
    "    return bert,xlnet,xlm,bart,electra,roberta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate = [ \n",
    "#' is a',\n",
    "#' is an',\n",
    "#' has class',\n",
    "#' has type',\n",
    "#' is a particular',\n",
    "#' is a specific',\n",
    "#' is an individual',\n",
    "#' is a unique',\n",
    "#' is an example of'\n",
    "#' has superclass'\n",
    "' is also a'\n",
    "' subtype of'\n",
    "' is a subtype of'\n",
    "' subcategory of'\n",
    "' is a category of'\n",
    "' is thereby also a'\n",
    "' is necessarily also a'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "testcount = 0\n",
    "bertcountlist = []\n",
    "xlnetcountlist = []\n",
    "xlmcountlist = []\n",
    "bartcountlist = []\n",
    "electracountlist = []\n",
    "robertacountlist = []\n",
    "\n",
    "LM_count1 = []\n",
    "LM_count2 = []\n",
    "LM_count3 = []\n",
    "LM_count4 = []\n",
    "LM_count5 = []\n",
    "LM_count6 = []\n",
    "WK_count = []\n",
    "\n",
    "r_wiki = random.sample(list(wikidata.items()), 1000)\n",
    "wikidata = dict(r_wiki)\n",
    "\n",
    "for key in wikidata.keys():\n",
    "    bertlist = set()\n",
    "    xlnetlist = set()\n",
    "    xlmlist = set()\n",
    "    bartlist = set()\n",
    "    electralist = set()\n",
    "    robertalist = set()\n",
    "    for i in range(len(predicate)) :\n",
    "        text_sentence = str(key) + predicate[i] + ' <mask>.'\n",
    "        bert,xlnet,xlm,bart,electra,roberta = get_all_predictions(text_sentence)\n",
    "        bertlist.update([bert[0],bert[1],bert[2]])\n",
    "        xlnetlist.update([xlnet[0],xlnet[1],xlnet[2]])\n",
    "        xlmlist.update([xlm[0],xlm[1],xlm[2]])\n",
    "        bartlist.update([bart[0],bart[1],bart[2]])\n",
    "        electralist.update([electra[0],electra[1],electra[2]])\n",
    "        robertalist.update([roberta[0],roberta[1],roberta[2]])\n",
    "    bertlist = list(bertlist)\n",
    "    xlnetlist = list(xlnetlist)\n",
    "    xlmlist = list(xlmlist)\n",
    "    bartlist = list(bartlist)\n",
    "    electralist = list(electralist)\n",
    "    robertalist = list(robertalist)\n",
    "    \n",
    "    LM_count1.append(len(bertlist))\n",
    "    LM_count2.append(len(xlnetlist))\n",
    "    LM_count3.append(len(xlmlist))\n",
    "    LM_count4.append(len(bartlist))\n",
    "    LM_count5.append(len(electralist))\n",
    "    LM_count6.append(len(robertalist))\n",
    "    WK_count.append(len(wikidata[key]))\n",
    "    \n",
    "    bertcount = 0\n",
    "    for j in range(len(bertlist)) :\n",
    "        if bertlist[j] in wikidata[key] :\n",
    "            bertcount += 1\n",
    "    bertcountlist.append(bertcount)\n",
    "    \n",
    "    xlnetcount = 0\n",
    "    for j in range(len(xlnetlist)) :\n",
    "        if xlnetlist[j] in wikidata[key] :\n",
    "            xlnetcount += 1\n",
    "    xlnetcountlist.append(xlnetcount)\n",
    "    \n",
    "    xlmcount = 0\n",
    "    for j in range(len(xlmlist)) :\n",
    "        if xlmlist[j] in wikidata[key] :\n",
    "            xlmcount += 1\n",
    "    xlmcountlist.append(xlmcount)\n",
    "    \n",
    "    bartcount = 0\n",
    "    for j in range(len(bartlist)) :\n",
    "        if bartlist[j] in wikidata[key] :\n",
    "            bartcount += 1\n",
    "    bartcountlist.append(bartcount)\n",
    "    \n",
    "    electracount = 0\n",
    "    for j in range(len(electralist)) :\n",
    "        if electralist[j] in wikidata[key] :\n",
    "            electracount += 1\n",
    "    electracountlist.append(electracount)\n",
    "    \n",
    "    robertacount = 0\n",
    "    for j in range(len(robertalist)) :\n",
    "        if robertalist[j] in wikidata[key] :\n",
    "            robertacount += 1\n",
    "    robertacountlist.append(robertacount)\n",
    "    \n",
    "    testcount += 1\n",
    "    if testcount == 100 :\n",
    "        break\n",
    "    \n",
    "\n",
    "bertAVG = sum(bertcountlist, 0.0)/len(bertcountlist)\n",
    "print(\"bertAverage :\", bertAVG)\n",
    "xlnetAVG = sum(xlnetcountlist, 0.0)/len(xlnetcountlist)\n",
    "print(\"xlnetAverage :\", xlnetAVG) \n",
    "xlmAVG = sum(xlmcountlist, 0.0)/len(xlmcountlist)\n",
    "print(\"xlmAverage :\", xlmAVG) \n",
    "bartAVG = sum(bartcountlist, 0.0)/len(bartcountlist)\n",
    "print(\"bartAverage :\", bartAVG)\n",
    "electraAVG = sum(electracountlist, 0.0)/len(electracountlist)\n",
    "print(\"electraAverage :\", electraAVG) \n",
    "robertaAVG = sum(robertacountlist, 0.0)/len(robertacountlist)\n",
    "print(\"robertaAverage :\", robertaAVG)\n",
    "\n",
    "AVG_WKlist = sum(WK_count, 0.0)/len(WK_count)\n",
    "print(\"AVG_WKlist :\", AVG_WKlist)\n",
    "AVG_LMlist1 = sum(LM_count1, 0.0)/len(LM_count1)\n",
    "print(\"AVG_LMlist1 :\", AVG_LMlist1)\n",
    "AVG_LMlist2 = sum(LM_count2, 0.0)/len(LM_count2)\n",
    "print(\"AVG_LMlist2 :\", AVG_LMlist2)\n",
    "AVG_LMlist3 = sum(LM_count3, 0.0)/len(LM_count3)\n",
    "print(\"AVG_LMlist3 :\", AVG_LMlist3)\n",
    "AVG_LMlist4 = sum(LM_count4, 0.0)/len(LM_count4)\n",
    "print(\"AVG_LMlist4 :\", AVG_LMlist4)\n",
    "AVG_LMlist5 = sum(LM_count5, 0.0)/len(LM_count5)\n",
    "print(\"AVG_LMlist5 :\", AVG_LMlist5)\n",
    "AVG_LMlist6 = sum(LM_count6, 0.0)/len(LM_count6)\n",
    "print(\"AVG_LMlist6 :\", AVG_LMlist6)\n",
    "\n",
    "Precision1 = bertAVG/AVG_WKlist\n",
    "print(\"Precision1 :\", Precision1)\n",
    "Precision2 = xlnetAVG/AVG_WKlist\n",
    "print(\"Precision2 :\", Precision2)\n",
    "Precision3 = xlmAVG/AVG_WKlist\n",
    "print(\"Precision3 :\", Precision3)\n",
    "Precision4 = bartAVG/AVG_WKlist\n",
    "print(\"Precision4 :\", Precision4)\n",
    "Precision5 = electraAVG/AVG_WKlist\n",
    "print(\"Precision5 :\", Precision5)\n",
    "Precision6 = robertaAVG/AVG_WKlist\n",
    "print(\"Precision6 :\", Precision6)\n",
    "\n",
    "Recall1 = bertAVG/AVG_LMlist1\n",
    "print(\"Recall1 :\", Recall1)\n",
    "Recall2 = xlnetAVG/AVG_LMlist2\n",
    "print(\"Recall2 :\", Recall2)\n",
    "Recall3 = xlmAVG/AVG_LMlist3\n",
    "print(\"Recall3 :\", Recall3)\n",
    "Recall4 = bartAVG/AVG_LMlist4\n",
    "print(\"Recall4 :\", Recall4)\n",
    "Recall5 = electraAVG/AVG_LMlist5\n",
    "print(\"Recall5 :\", Recall5)\n",
    "Recall6 = robertaAVG/AVG_LMlist6\n",
    "print(\"Recall6 :\", Recall6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
